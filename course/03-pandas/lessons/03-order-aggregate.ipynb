{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "parks_df = pd.read_parquet(\"../../data/nps/nps_public_data_parks.parquet\")\n",
    "parks_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coming directly from a SQL module on transformation, we'll approach aggregations similarly via Pandas— that means we're assuming you've completed module 2 _or_ have a basic understanding of SQL `GROUP` functionality.\n",
    "\n",
    "Pandas `groupby` works quite similarly to SQL, with a Pythonic twist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the groupby method, we specify the column we want to group by, and then the column we want to count in brackets.\n",
    "\n",
    "parks_df.groupby(\"states\")[\"states\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we'll need to do something similar with states here, but think in terms of Python— create a new column by _splitting_ `states` on the comma separator to convert it to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_df[\"states_list\"] = parks_df[\"states\"].str.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_df[\"states_list\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform an `explode` like we did in lesson 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_exploded_df = parks_df.explode(\"states_list\").rename(\n",
    "    columns={\"states_list\": \"state\"}\n",
    ")\n",
    "parks_exploded_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can perform a groupby in pandas:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_exploded_df.groupby(\"state\")[\"state\"].count()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we used the slice to obtain the top 5 results. We can sort the results of _any_ dataframe using `sort_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_exploded_df.groupby(\"state\")[\"state\"].count().sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we only want those designated as National Parks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_park_count_df = (\n",
    "    parks_exploded_df[parks_exploded_df[\"designation\"] == \"National Park\"]\n",
    "    .groupby(\"state\")[\"state\"]\n",
    "    .count()\n",
    "    .sort_values(ascending=False)[:5]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how we formatted our query— by using parenthesis `()`, we were able to split the query into multiple lines and organize the operations. That makes it much easier to read then the alternative. The same can be accomplished with backslashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_park_count_df = (\n",
    "    parks_exploded_df[parks_exploded_df[\"designation\"] == \"National Park\"]\n",
    "    .groupby(\"state\")[\"state\"]\n",
    "    .count()\n",
    "    .sort_values(ascending=False)[:5]\n",
    ")\n",
    "\n",
    "national_park_count_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like our earlier example, let's find campgrounds with the least & most sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campgrounds_df = pd.read_parquet(\"../../data/nps/nps_public_data_campgrounds.parquet\")\n",
    "campgrounds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campgrounds_df[\"total_sites\"] = (\n",
    "    campgrounds_df[\"numberOfSitesFirstComeFirstServe\"]\n",
    "    + campgrounds_df[\"numberOfSitesReservable\"]\n",
    ")\n",
    "\n",
    "national_park_campgrounds_df = campgrounds_df.merge(\n",
    "    parks_df, on=\"parkCode\", how=\"inner\", suffixes=(\"_campground\", \"_park\")\n",
    ")\n",
    "\n",
    "national_park_campgrounds_df = national_park_campgrounds_df[\n",
    "    (national_park_campgrounds_df[\"designation\"] == \"National Park\")\n",
    "    & (national_park_campgrounds_df[\"total_sites\"] > 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sites = national_park_campgrounds_df[\"total_sites\"].min()\n",
    "\n",
    "max_sites = national_park_campgrounds_df[\"total_sites\"].max()\n",
    "\n",
    "min_max_df = national_park_campgrounds_df[\n",
    "    (national_park_campgrounds_df[\"total_sites\"] == min_sites)\n",
    "    | (national_park_campgrounds_df[\"total_sites\"] == max_sites)\n",
    "]\n",
    "\n",
    "min_max_df[\"min_max\"] = np.where(\n",
    "    min_max_df[\"total_sites\"] == min_sites,\n",
    "    \"min\",\n",
    "    np.where(min_max_df[\"total_sites\"] == max_sites, \"max\", \"other\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_df[[\"fullName\", \"name_campground\", \"total_sites\", \"min_max\"]].sort_values(\n",
    "    by=\"total_sites\", ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the parks? Now, we just need to group by park!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sites_park = national_park_campgrounds_df.groupby([\"fullName\"])[\"total_sites\"].min()\n",
    "\n",
    "max_sites_park = national_park_campgrounds_df.groupby([\"fullName\"])[\"total_sites\"].max()\n",
    "\n",
    "park_campgrounds_agg = (\n",
    "    national_park_campgrounds_df.groupby(\"fullName\")[\"total_sites\"]\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "park_campgrounds_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groupby is pretty similar to the SQL equivalent! You can perform all sorts of basic groups. If you'd like to play around with more Groupby examples, check out the Pandas [docs](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lil-cdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
